{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 时间跨度\n",
    "    - 历史数据中包含`('2017-01-01 00:00:00', '2018-03-27 05:00:00')`的天气数据\n",
    "    - API 下载数据中包含 `'2017-04-01 00:00:00'` 以后的数据\n",
    "    - 拟使用四月的数据作为 dev set，历史数据作为训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from utils.weather_data_util import load_bj_grid_meo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 首先加载使用到的 meo 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "near_stations = {'aotizhongxin_aq': 'beijing_grid_304',\n",
    " 'badaling_aq': 'beijing_grid_224',\n",
    " 'beibuxinqu_aq': 'beijing_grid_263',\n",
    " 'daxing_aq': 'beijing_grid_301',\n",
    " 'dingling_aq': 'beijing_grid_265',\n",
    " 'donggaocun_aq': 'beijing_grid_452',\n",
    " 'dongsi_aq': 'beijing_grid_303',\n",
    " 'dongsihuan_aq': 'beijing_grid_324',\n",
    " 'fangshan_aq': 'beijing_grid_238',\n",
    " 'fengtaihuayuan_aq': 'beijing_grid_282',\n",
    " 'guanyuan_aq': 'beijing_grid_282',\n",
    " 'gucheng_aq': 'beijing_grid_261',\n",
    " 'huairou_aq': 'beijing_grid_349',\n",
    " 'liulihe_aq': 'beijing_grid_216',\n",
    " 'mentougou_aq': 'beijing_grid_240',\n",
    " 'miyun_aq': 'beijing_grid_392',\n",
    " 'miyunshuiku_aq': 'beijing_grid_414',\n",
    " 'nansanhuan_aq': 'beijing_grid_303',\n",
    " 'nongzhanguan_aq': 'beijing_grid_324',\n",
    " 'pingchang_aq': 'beijing_grid_264',\n",
    " 'pinggu_aq': 'beijing_grid_452',\n",
    " 'qianmen_aq': 'beijing_grid_303',\n",
    " 'shunyi_aq': 'beijing_grid_368',\n",
    " 'tiantan_aq': 'beijing_grid_303',\n",
    " 'tongzhou_aq': 'beijing_grid_366',\n",
    " 'wanliu_aq': 'beijing_grid_283',\n",
    " 'wanshouxigong_aq': 'beijing_grid_303',\n",
    " 'xizhimenbei_aq': 'beijing_grid_283',\n",
    " 'yanqin_aq': 'beijing_grid_225',\n",
    " 'yizhuang_aq': 'beijing_grid_323',\n",
    " 'yongdingmennei_aq': 'beijing_grid_303',\n",
    " 'yongledian_aq': 'beijing_grid_385',\n",
    " 'yufa_aq': 'beijing_grid_278',\n",
    " 'yungang_aq': 'beijing_grid_239',\n",
    " 'zhiwuyuan_aq': 'beijing_grid_262'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bj_meo_stations : meo_station as key and df as value \n",
    "bj_grid_meo_dataset, stations, bj_meo_stations = load_bj_grid_meo_data(near_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-04-23 23:00:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_grid_meo_dataset.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zhiwuyuan_aq_temperature</th>\n",
       "      <th>zhiwuyuan_aq_pressure</th>\n",
       "      <th>zhiwuyuan_aq_humidity</th>\n",
       "      <th>zhiwuyuan_aq_wind_direction</th>\n",
       "      <th>zhiwuyuan_aq_wind_speed/kph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>-6.01</td>\n",
       "      <td>1003.24</td>\n",
       "      <td>69.97</td>\n",
       "      <td>129.93</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>-3.19</td>\n",
       "      <td>1003.12</td>\n",
       "      <td>58.66</td>\n",
       "      <td>147.40</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>1003.00</td>\n",
       "      <td>47.35</td>\n",
       "      <td>166.69</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>2.45</td>\n",
       "      <td>1002.89</td>\n",
       "      <td>36.04</td>\n",
       "      <td>183.97</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>3.55</td>\n",
       "      <td>1002.25</td>\n",
       "      <td>33.61</td>\n",
       "      <td>154.96</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     zhiwuyuan_aq_temperature  zhiwuyuan_aq_pressure  \\\n",
       "time                                                                   \n",
       "2017-01-01 00:00:00                     -6.01                1003.24   \n",
       "2017-01-01 01:00:00                     -3.19                1003.12   \n",
       "2017-01-01 02:00:00                     -0.37                1003.00   \n",
       "2017-01-01 03:00:00                      2.45                1002.89   \n",
       "2017-01-01 04:00:00                      3.55                1002.25   \n",
       "\n",
       "                     zhiwuyuan_aq_humidity  zhiwuyuan_aq_wind_direction  \\\n",
       "time                                                                      \n",
       "2017-01-01 00:00:00                  69.97                       129.93   \n",
       "2017-01-01 01:00:00                  58.66                       147.40   \n",
       "2017-01-01 02:00:00                  47.35                       166.69   \n",
       "2017-01-01 03:00:00                  36.04                       183.97   \n",
       "2017-01-01 04:00:00                  33.61                       154.96   \n",
       "\n",
       "                     zhiwuyuan_aq_wind_speed/kph  \n",
       "time                                              \n",
       "2017-01-01 00:00:00                         1.51  \n",
       "2017-01-01 01:00:00                         1.37  \n",
       "2017-01-01 02:00:00                         1.38  \n",
       "2017-01-01 03:00:00                         1.53  \n",
       "2017-01-01 04:00:00                         2.27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_meo_stations['zhiwuyuan_aq'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bj_meo_stations.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 重复值分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 识别重复值的数量，并将重复值去掉\n",
    "- meo 数据中没有重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq 重复数量 : 0\n",
      "liulihe_aq 重复数量 : 0\n",
      "beibuxinqu_aq 重复数量 : 0\n",
      "badaling_aq 重复数量 : 0\n",
      "shunyi_aq 重复数量 : 0\n",
      "yongdingmennei_aq 重复数量 : 0\n",
      "fangshan_aq 重复数量 : 0\n",
      "wanliu_aq 重复数量 : 0\n",
      "qianmen_aq 重复数量 : 0\n",
      "donggaocun_aq 重复数量 : 0\n",
      "gucheng_aq 重复数量 : 0\n",
      "nansanhuan_aq 重复数量 : 0\n",
      "guanyuan_aq 重复数量 : 0\n",
      "dongsihuan_aq 重复数量 : 0\n",
      "nongzhanguan_aq 重复数量 : 0\n",
      "yizhuang_aq 重复数量 : 0\n",
      "yanqin_aq 重复数量 : 0\n",
      "miyun_aq 重复数量 : 0\n",
      "mentougou_aq 重复数量 : 0\n",
      "yufa_aq 重复数量 : 0\n",
      "aotizhongxin_aq 重复数量 : 0\n",
      "wanshouxigong_aq 重复数量 : 0\n",
      "zhiwuyuan_aq 重复数量 : 0\n",
      "tiantan_aq 重复数量 : 0\n",
      "huairou_aq 重复数量 : 0\n",
      "daxing_aq 重复数量 : 0\n",
      "miyunshuiku_aq 重复数量 : 0\n",
      "xizhimenbei_aq 重复数量 : 0\n",
      "tongzhou_aq 重复数量 : 0\n",
      "yungang_aq 重复数量 : 0\n",
      "dingling_aq 重复数量 : 0\n",
      "fengtaihuayuan_aq 重复数量 : 0\n",
      "pingchang_aq 重复数量 : 0\n",
      "yongledian_aq 重复数量 : 0\n",
      "pinggu_aq 重复数量 : 0\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys() :\n",
    "    \n",
    "    df = bj_meo_stations[station].copy()\n",
    "    length = df.shape[0]\n",
    "    order = range(length)\n",
    "    df['order'] = pd.Series(order, index=df.index)    \n",
    "    \n",
    "    \n",
    "    df[\"time\"] = df.index\n",
    "    df.set_index(\"order\", inplace=True)\n",
    "    \n",
    "    length_1 = df.shape[0]\n",
    "    # print(\"重复值去除之前，共有数据数量\", df.shape[0])\n",
    "    \n",
    "    used_times = []\n",
    "    for index in df.index :\n",
    "        time = df.loc[index][\"time\"]\n",
    "        if time not in used_times :\n",
    "            used_times.append(time)\n",
    "        else : \n",
    "            df.drop([index], inplace=True)\n",
    "\n",
    "    length_2 = df.shape[0]\n",
    "    delta = length_1 - length_2\n",
    "    # print(\"重复值去除之后，共有数据数量\", df.shape[0])\n",
    "    print(\"%s 重复数量 : %d\" %(station, delta))\n",
    "    \n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    bj_meo_stations[station] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 缺失值分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 局部缺失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判断有没有局部缺失：没有局部缺失！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq False\n",
      "liulihe_aq False\n",
      "beibuxinqu_aq False\n",
      "badaling_aq False\n",
      "shunyi_aq False\n",
      "yongdingmennei_aq False\n",
      "fangshan_aq False\n",
      "wanliu_aq False\n",
      "qianmen_aq False\n",
      "donggaocun_aq False\n",
      "gucheng_aq False\n",
      "nansanhuan_aq False\n",
      "guanyuan_aq False\n",
      "dongsihuan_aq False\n",
      "nongzhanguan_aq False\n",
      "yizhuang_aq False\n",
      "yanqin_aq False\n",
      "miyun_aq False\n",
      "mentougou_aq False\n",
      "yufa_aq False\n",
      "aotizhongxin_aq False\n",
      "wanshouxigong_aq False\n",
      "zhiwuyuan_aq False\n",
      "tiantan_aq False\n",
      "huairou_aq False\n",
      "daxing_aq False\n",
      "miyunshuiku_aq False\n",
      "xizhimenbei_aq False\n",
      "tongzhou_aq False\n",
      "yungang_aq False\n",
      "dingling_aq False\n",
      "fengtaihuayuan_aq False\n",
      "pingchang_aq False\n",
      "yongledian_aq False\n",
      "pinggu_aq False\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys():\n",
    "    df = bj_meo_stations[station]\n",
    "    print(station, pd.isnull(df).any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 整体缺失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计缺失小时的连续值\n",
    "- 如果一个缺失小时在一个长度小于等于5小时的缺失时段内，就进行补全\n",
    "- 如果超过5小时，就舍弃，将全部值补成 NAN，**这也是整个表中唯一可能出现 NAN 的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq 缺失时间节点数量是 121\n",
      "liulihe_aq 缺失时间节点数量是 121\n",
      "beibuxinqu_aq 缺失时间节点数量是 121\n",
      "badaling_aq 缺失时间节点数量是 121\n",
      "shunyi_aq 缺失时间节点数量是 121\n",
      "yongdingmennei_aq 缺失时间节点数量是 121\n",
      "fangshan_aq 缺失时间节点数量是 121\n",
      "wanliu_aq 缺失时间节点数量是 121\n",
      "qianmen_aq 缺失时间节点数量是 121\n",
      "donggaocun_aq 缺失时间节点数量是 121\n",
      "gucheng_aq 缺失时间节点数量是 121\n",
      "nansanhuan_aq 缺失时间节点数量是 121\n",
      "guanyuan_aq 缺失时间节点数量是 121\n",
      "dongsihuan_aq 缺失时间节点数量是 121\n",
      "nongzhanguan_aq 缺失时间节点数量是 121\n",
      "yizhuang_aq 缺失时间节点数量是 121\n",
      "yanqin_aq 缺失时间节点数量是 121\n",
      "miyun_aq 缺失时间节点数量是 121\n",
      "mentougou_aq 缺失时间节点数量是 122\n",
      "yufa_aq 缺失时间节点数量是 121\n",
      "aotizhongxin_aq 缺失时间节点数量是 122\n",
      "wanshouxigong_aq 缺失时间节点数量是 121\n",
      "zhiwuyuan_aq 缺失时间节点数量是 121\n",
      "tiantan_aq 缺失时间节点数量是 121\n",
      "huairou_aq 缺失时间节点数量是 121\n",
      "daxing_aq 缺失时间节点数量是 121\n",
      "miyunshuiku_aq 缺失时间节点数量是 121\n",
      "xizhimenbei_aq 缺失时间节点数量是 121\n",
      "tongzhou_aq 缺失时间节点数量是 121\n",
      "yungang_aq 缺失时间节点数量是 121\n",
      "dingling_aq 缺失时间节点数量是 121\n",
      "fengtaihuayuan_aq 缺失时间节点数量是 121\n",
      "pingchang_aq 缺失时间节点数量是 121\n",
      "yongledian_aq 缺失时间节点数量是 121\n",
      "pinggu_aq 缺失时间节点数量是 121\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys() :\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    \n",
    "    min_time = df.index.min()\n",
    "    max_time = df.index.max()\n",
    "\n",
    "    min_time = datetime.datetime.strptime(min_time, '%Y-%m-%d %H:%M:%S')\n",
    "    max_time = datetime.datetime.strptime(max_time, '%Y-%m-%d %H:%M:%S')\n",
    "    delta_all = max_time - min_time\n",
    "    \n",
    "    all_length = delta_all.total_seconds()/3600 + 1\n",
    "    real_length = df.shape[0]\n",
    "    # print(\"在空气质量数据时间段内，总共应该有 %d 个小时节点。\" %(all_length))\n",
    "    # print(\"实际的时间节点数是 \", real_length)\n",
    "    print(\"%s 缺失时间节点数量是 %d\" %(station, all_length-real_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 整体缺失补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq (11351, 5)\n",
      "liulihe_aq (11351, 5)\n",
      "beibuxinqu_aq (11351, 5)\n",
      "badaling_aq (11351, 5)\n",
      "shunyi_aq (11351, 5)\n",
      "yongdingmennei_aq (11351, 5)\n",
      "fangshan_aq (11351, 5)\n",
      "wanliu_aq (11351, 5)\n",
      "qianmen_aq (11351, 5)\n",
      "donggaocun_aq (11351, 5)\n",
      "gucheng_aq (11351, 5)\n",
      "nansanhuan_aq (11351, 5)\n",
      "guanyuan_aq (11351, 5)\n",
      "dongsihuan_aq (11351, 5)\n",
      "nongzhanguan_aq (11351, 5)\n",
      "yizhuang_aq (11351, 5)\n",
      "yanqin_aq (11351, 5)\n",
      "miyun_aq (11351, 5)\n",
      "mentougou_aq (11350, 5)\n",
      "yufa_aq (11351, 5)\n",
      "aotizhongxin_aq (11350, 5)\n",
      "wanshouxigong_aq (11351, 5)\n",
      "zhiwuyuan_aq (11351, 5)\n",
      "tiantan_aq (11351, 5)\n",
      "huairou_aq (11351, 5)\n",
      "daxing_aq (11351, 5)\n",
      "miyunshuiku_aq (11351, 5)\n",
      "xizhimenbei_aq (11351, 5)\n",
      "tongzhou_aq (11351, 5)\n",
      "yungang_aq (11351, 5)\n",
      "dingling_aq (11351, 5)\n",
      "fengtaihuayuan_aq (11351, 5)\n",
      "pingchang_aq (11351, 5)\n",
      "yongledian_aq (11351, 5)\n",
      "pinggu_aq (11351, 5)\n"
     ]
    }
   ],
   "source": [
    "for station in bj_meo_stations.keys() :\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    print(station, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongsi_aq : length of data is 11472\n",
      "liulihe_aq : length of data is 11472\n",
      "beibuxinqu_aq : length of data is 11472\n",
      "badaling_aq : length of data is 11472\n",
      "shunyi_aq : length of data is 11472\n",
      "yongdingmennei_aq : length of data is 11472\n",
      "fangshan_aq : length of data is 11472\n",
      "wanliu_aq : length of data is 11472\n",
      "qianmen_aq : length of data is 11472\n",
      "donggaocun_aq : length of data is 11472\n",
      "gucheng_aq : length of data is 11472\n",
      "nansanhuan_aq : length of data is 11472\n",
      "guanyuan_aq : length of data is 11472\n",
      "dongsihuan_aq : length of data is 11472\n",
      "nongzhanguan_aq : length of data is 11472\n",
      "yizhuang_aq : length of data is 11472\n",
      "yanqin_aq : length of data is 11472\n",
      "miyun_aq : length of data is 11472\n",
      "mentougou_aq : length of data is 11472\n",
      "yufa_aq : length of data is 11472\n",
      "aotizhongxin_aq : length of data is 11472\n",
      "wanshouxigong_aq : length of data is 11472\n",
      "zhiwuyuan_aq : length of data is 11472\n",
      "tiantan_aq : length of data is 11472\n",
      "huairou_aq : length of data is 11472\n",
      "daxing_aq : length of data is 11472\n",
      "miyunshuiku_aq : length of data is 11472\n",
      "xizhimenbei_aq : length of data is 11472\n",
      "tongzhou_aq : length of data is 11472\n",
      "yungang_aq : length of data is 11472\n",
      "dingling_aq : length of data is 11472\n",
      "fengtaihuayuan_aq : length of data is 11472\n",
      "pingchang_aq : length of data is 11472\n",
      "yongledian_aq : length of data is 11472\n",
      "pinggu_aq : length of data is 11472\n"
     ]
    }
   ],
   "source": [
    "delta = datetime.timedelta(hours=1)\n",
    "\n",
    "for station in bj_meo_stations.keys() :\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    nan_series = pd.Series({key:np.nan for key in df.columns})\n",
    "    \n",
    "    min_time = df.index.min()\n",
    "    max_time = df.index.max()\n",
    "\n",
    "    min_time = datetime.datetime.strptime(min_time, '%Y-%m-%d %H:%M:%S')\n",
    "    max_time = datetime.datetime.strptime(max_time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    time = min_time\n",
    "    \n",
    "    while time <=  max_time :\n",
    "        \n",
    "        time_str = datetime.date.strftime(time, '%Y-%m-%d %H:%M:%S')\n",
    "        if time_str not in df.index :\n",
    "            \n",
    "            # 前边第几个是非空的\n",
    "            found_for = False\n",
    "            i = 0\n",
    "            while not found_for :\n",
    "                i += 1\n",
    "                for_time = time - i * delta\n",
    "                for_time_str = datetime.date.strftime(for_time, '%Y-%m-%d %H:%M:%S')\n",
    "                if for_time_str in df.index :\n",
    "                    for_row = df.loc[for_time_str]\n",
    "                    for_step = i\n",
    "                    found_for = True\n",
    "\n",
    "            # 后边第几个是非空的\n",
    "            found_back = False\n",
    "            j = 0\n",
    "            while not found_back :\n",
    "                j += 1\n",
    "                back_time = time + j * delta\n",
    "                back_time_str = datetime.date.strftime(back_time, '%Y-%m-%d %H:%M:%S')\n",
    "                if back_time_str in df.index :\n",
    "                    back_row = df.loc[back_time_str]\n",
    "                    back_step = j\n",
    "                    found_back = True\n",
    "        \n",
    "            all_steps = for_step + back_step\n",
    "        \n",
    "            if all_steps <= 5 :\n",
    "                delata_values = back_row - for_row\n",
    "                df.loc[time_str] = for_row + (for_step/all_steps) * delata_values\n",
    "            else :\n",
    "                df.loc[time_str] = nan_series\n",
    "        \n",
    "        time += delta\n",
    "    bj_meo_stations[station] = df\n",
    "    \n",
    "    print(\"%s : length of data is %d\" %(station, df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 风向缺失值处理\n",
    "- 暂时使用 0 替换缺失的风向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for station in bj_meo_stations.keys():\n",
    "    df = bj_meo_stations[station].copy()\n",
    "    df.replace(999017,0, inplace=True)\n",
    "    bj_meo_stations[station] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 拼成整表，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bj_meo_stations_merged = pd.concat(list(bj_meo_stations.values()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11472, 175)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_meo_stations_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bj_meo_stations_merged.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bj_meo_stations_merged.to_csv(\"data/bj_meo_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要将 `bj_meo_data.csv`左上角位置的空格补上 \"time\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe = bj_meo_stations_merged.describe()\n",
    "describe.to_csv(\"data/bj_meo_describe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_norm = (bj_meo_stations_merged - describe.loc['mean']) / describe.loc['std']\n",
    "df_norm.to_csv(\"data/bj_meo_norm_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelog\n",
    "- 0425 v0\n",
    "    - 天气数据的缺失值补全\n",
    "    - 将数据保存到 `data/bj_meo_data.csv`中\n",
    "- 0426 v0.1\n",
    "    - 增加数据正则化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
